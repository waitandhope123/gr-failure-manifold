# Phase 8 — Numerical Methods & Validation

**Toys 041–050**

---

## Toy 041 — Coordinate invariance regression test

This toy evaluates curvature invariants of the Schwarzschild spacetime at a set of radii and checks that the results are identical across multiple coordinate charts that describe the same geometry. The physical setup is a vacuum black-hole spacetime with mass parameter $M$ (in units with $G=c=1$), sampled at coordinate radius $r$, and the main quantity of interest is the Kretschmann scalar $K$, which for Schwarzschild is $K=48M^2/r^6$ (alongside the Ricci scalar $R$, which is zero in vacuum).

The toy exists to stress-test the codebase’s coordinate handling: changing coordinates should not change invariants, but implementation bugs can accidentally introduce chart-dependent artifacts (e.g., incorrect transformations, sign conventions, or mixing coordinate and orthonormal components). Conceptually, it demonstrates the principle that scalar invariants should be chart-independent even when intermediate metric components differ, i.e., if two charts represent the same spacetime then the computed scalars should satisfy $K_{\mathrm{chart\ A}}(r)=K_{\mathrm{chart\ B}}(r)$ within a prescribed numerical tolerance. Any failure here is treated as a limitation or regression in the implementation, not as a physical effect.

To interpret the JSON, focus on each entry in `sample_points`: it records the sampled `coordinates.r` and a `curvature_invariants.kretschmann_by_chart` map giving $(K,R)$ for each chart, plus `consistent_within_tolerance` and the `tolerance` used for the pass/fail check. The meaningful trends are that $K$ should fall rapidly with increasing $r$ (roughly like $r^{-6}$ at fixed $M$) and grow with $M$ (roughly like $M^2$), while the per-chart values should match to within the tolerance; the top-level `observables.summary.all_points_invariant_consistent` should remain true when the implementation is healthy, and `horizon_radius_2M` provides the reference scale $2M$. Do not over-interpret the absolute numbers as “predictions” beyond this sanity check: the toy does not model dynamics, observables, or causal structure, and agreement here only indicates that the scalar computations are coordinate-invariant in this limited setup, connecting the stored values back to the defining relation $K=48M^2/r^6$ and the vacuum expectation $R=0$.

---

## Toy 042 — Numerical Stability Near Horizons and Singular Limits

This toy evaluates a simple curvature diagnostic in Schwarzschild spacetime to probe how numerical calculations behave near extreme geometric regions. The physical setup is a non-rotating black hole with mass $M$, sampled at a range of radial coordinates $r$, including points near the event horizon and deep toward the central singularity. The quantity of interest is the Kretschmann scalar, a curvature invariant that grows rapidly at small radius, given by $K = 48 M^2 / r^6$, which serves here as a clean, analytic signal against which numerical behavior can be judged.

The toy exists to illustrate a limitation of numerical diagnostics rather than to make a physical claim about black holes. Although $K$ diverges only as $r \to 0$, finite-difference probes of $K$ can become unstable or misleading well before that limit is reached. The conceptual stress test is whether a numerical sensitivity measure, defined schematically as $|K(r+\epsilon)-K(r)|/(|K(r)|\epsilon)$ with $\epsilon$ a small step size, reflects true geometric steepness or instead amplifies floating-point error and subtraction loss. The toy exposes how numerical breakdown can occur near horizons or steep gradients even when the underlying quantity remains finite.

The JSON output should be read as a structured set of samples rather than as predictions. The `kretschmann` values illustrate the expected monotonic growth as $r$ decreases, while the `relative_sensitivity` tracks how sharply that quantity responds to small coordinate changes. Large or rapidly increasing sensitivity values signal numerical fragility, not new physics, and flags such as `near_horizon` or `near_singularity` only indicate proximity by coordinate thresholds. Users should not over-interpret exact magnitudes or minor asymmetries; instead, the important trend is how the sensitivity scales consistently with the $r^{-6}$ dependence of $K$, demonstrating where numerical differentiation becomes unreliable relative to the underlying analytic behavior.

---

## Toy 043 — Same infall, different clocks: foliation-dependent time evolution

This toy follows a single radial infall trajectory in Schwarzschild spacetime (vacuum, $G=c=1$) and reports how the “time elapsed” along that same physical motion depends on which time coordinate you choose to label spacetime slices. The setup is an idealized timelike geodesic dropped from rest at infinity, encoded here by conserved energy $E=1$, sampled at decreasing radii $r$ starting from $r_\mathrm{start}$. The quantity of interest is not the motion itself (which is fixed), but the map from radius to several time variables—especially the contrast between finite proper time and potentially divergent coordinate time near the horizon at $r=2M$.

The toy exists to illustrate a conceptual pitfall: coordinate-time behavior can look like a dynamical “freeze” even when nothing pathological happens to the infalling object. In Schwarzschild coordinates the time label is tied to a foliation that becomes singular at the horizon, which makes the same infall appear to take arbitrarily long in $t$ as $r\to 2M$, even though the infaller reaches the horizon in finite proper time. That stress test is the limitation being exposed: the divergence is a foliation artifact, not a physical prediction, and horizon-regular slicings are designed precisely to avoid that failure mode.

To interpret the JSON, read each `sample_points[i]` as one radius snapshot with `proper_time_tau_from_r_start`, `schwarzschild_time_t_from_r_start`, `pg_time_t_pg_from_r_start`, and `ef_advanced_time_v_from_r_start` shifted so they are zero at $r=r_\mathrm{start}$. The key trend is that $\tau$ should grow to a finite value as you approach $r=2M$ (e.g., it levels off near $\sim 13.57$ for the provided sampling), while `schwarzschild_time_t_from_r_start` grows rapidly as $r$ gets close to $2M$ (e.g., increasing from $\sim 0$ at $r=10$ to $\sim 39$ by $r=2.0001$), demonstrating the coordinate-time blow-up; in contrast `pg_time_t_pg_from_r_start` and `ef_advanced_time_v_from_r_start` remain finite and comparatively gentle, reflecting horizon-regular foliations. You should not over-interpret the absolute offsets, the particular numerical values far from the horizon, or the near-horizon growth rate as “physics”; what matters is the sign and relative magnitude of the divergence pattern across slicings, and the fact that the curvature invariants (`ricci_scalar_R = 0` and finite `kretschmann_K`) stay well-behaved, reinforcing that the geometry and the worldline are unchanged while only the time labeling differs.

---

## Toy 044 — Finite-Size Observer and Instrument Breakdown Under Tidal Gradients

This toy illustrates how a finite-size observer or instrument behaves in a curved spacetime where tidal gradients are present. The physical setup is a static observer outside a Schwarzschild black hole, equipped with an idealized instrument modeled as a rigid rod of length $L$ aligned radially. The quantity of interest is the differential acceleration induced across the instrument by spacetime curvature, estimated using the radial component of the tidal tensor as $a_\mathrm{diff} \approx |E_{rr}|\,L$, where $E_{rr}$ measures radial stretching in the observer’s local orthonormal frame.

The toy exists to expose a limitation of the equivalence principle when applied operationally rather than abstractly. While the equivalence principle protects pointlike observers from detecting gravity locally, any extended body inevitably samples curvature gradients, leading to internal stresses or clock desynchronization. This model is a stress test rather than a physical prediction: it demonstrates how operational validity becomes scale-dependent, controlled by the instrument size $L$ and a tolerable threshold $a_\mathrm{max}$, even in regions where scalar curvature measures remain modest and well behaved.

The JSON results should be read as a structured record of where the instrument remains operational under this criterion. The key trends are the monotonic growth of the tidal components $E_{rr} \propto 1/r^3$ and the associated increase in $a_\mathrm{diff}$ as the radius approaches $2M$, with a sharp cutoff where static observers are no longer defined. The sign of the tidal components encodes stretching versus compression but is less important here than the magnitude relative to $a_\mathrm{max}$. These outputs should not be over-interpreted as survival limits or physical predictions near horizons; they only indicate where the simple inequality $|E_{rr}|\,L \le a_\mathrm{max}$ is satisfied, linking the numerical JSON values back to the conceptual tidal-acceleration estimate.

---

## Toy 045 — Constraint Propagation and Drift in Linearized Gravity

This toy illustrates how gauge constraints behave in a simplified model inspired by linearized general relativity in harmonic gauge. The physical setup replaces the full tensor system by a single representative constraint field $C(t,x)$ evolving on a one-dimensional periodic domain, meant to stand in for the harmonic gauge conditions $C_\mu = \partial^\nu \bar{h}_{\mu\nu}$. The quantity of interest is not the metric perturbation itself, but the size of constraint violations as they evolve according to a wave-like equation, either undamped or with an added friction term, schematically $C_{tt} = C_{xx}$ or $C_{tt} + \kappa C_t = C_{xx}$.

The toy exists to expose a conceptual pressure point in constrained evolution systems: constraints are not automatically enforced by time evolution. Even in this linearized and highly controlled setting, an initial violation does not disappear on its own but propagates indefinitely, reflecting the fact that the constraint subsystem satisfies its own hyperbolic equation. The addition of a damping term is not a physical prediction but a deliberate stress test of a common numerical-relativity strategy, showing how modifying the constraint evolution equation can actively suppress violations without changing the underlying physical equations.

The JSON results should be read as diagnostics of constraint behavior over time rather than as physical observables. The time series labeled by L2 and Linf norms track the overall magnitude and peak size of $C(t,x)$ for undamped and damped evolutions, and the key trend is the contrast between persistence in the undamped case and monotonic decay when $\kappa>0$. Absolute values, detailed oscillations, or late-time plateaus should not be over-interpreted as predictions about gravity; they reflect numerical choices and the proxy model. Conceptually, the reported norms quantify how solutions of the constraint equations mirror the structure of the wave equations above, making explicit how constraint damping changes their qualitative behavior.

---

## Toy 046 — Comparing gravitational “energy” notions in Schwarzschild

This toy evaluates several standard mass/energy definitions for the Schwarzschild vacuum spacetime (geometric units $G=c=1$) and reports how they behave when you ask for “the energy inside a sphere” of areal radius $r$. The physical setup is intentionally simple: a black-hole exterior characterized by a single parameter $M$, and a family of concentric 2-spheres labeled by $r$. The quantity of interest is not a field or flux, but the numerical value assigned to mass/energy by different definitions—most notably the Brown–York quasilocal energy on a sphere, $E_{\mathrm{BY}}(r)=r\left(1-\sqrt{1-2M/r}\right)$ for $r>2M$.

The toy exists to demonstrate that “gravitational energy” in general relativity is not uniquely defined quasi-locally, even when the spacetime is as symmetric and well-behaved as Schwarzschild. It stresses a conceptual failure mode: global notions (ADM and Komar) can agree and equal $M$ while a quasilocal notion can differ at finite radius, without any contradiction—because the definitions answer slightly different questions and rely on different structure (e.g., asymptotics, Killing symmetries, or reference embeddings). Read the output as a limitation test of locality and interpretation, not a physical prediction; the key principle is that agreement at infinity does not guarantee agreement at finite $r$, even though $M_{\mathrm{ADM}}=M_{\mathrm{Komar}}=M$ in this setup.

To interpret the JSON, focus on `sample_points[*].local_observables.mass_definitions` and the corresponding `deltas_from_M`: ADM, Komar, and Misner–Sharp are constant and equal to `M_parameter`, while `Brown_York_energy` is larger than $M$ near the horizon and monotonically approaches $M$ as $r$ increases (track `Brown_York_minus_M` and the summary field `brown_york_abs_error_last_defined`). The sign matters: a positive `Brown_York_minus_M` here indicates the quasilocal value exceeds the parameter $M$ on finite spheres in this slicing/reference choice, while the trend toward zero at large $r$ reflects the asymptotic limit of the formula. Do not over-interpret the near-horizon magnitude as “extra physical energy” or as a unique measure of binding energy; instead, connect the reported values back to the single anchor equation for $E_{\mathrm{BY}}(r)$ and treat the deltas as a quantitative readout of definitional ambiguity at finite radius.

---

## Toy 047 — Observer-dependent Operational Horizons

This toy illustrates how different observers operationally identify “horizon-like” surfaces in a Schwarzschild spacetime, even though the event horizon itself is a global causal structure. The physical setup fixes a Schwarzschild mass $M$ and samples emission radii $r_\mathrm{emit}$ while comparing what various observers can register. For a static observer at radius $r_\mathrm{obs}$, the quantity of interest is the gravitational redshift of photons, summarized by the ratio $\nu_\mathrm{obs}/\nu_\mathrm{emit}=\sqrt{f(r_\mathrm{emit})/f(r_\mathrm{obs})}$ with $f(r)=1-2M/r$, which decreases smoothly as emission approaches the horizon at $r=2M$.

The toy exists to expose a conceptual limitation: horizons are not locally measurable objects, yet practical observers often define them through operational criteria tied to finite instruments or coordinate choices. By introducing a detector cutoff for redshift, a freely falling observer’s “no-return” condition, and a uniformly accelerated observer’s Rindler horizon, the model stresses that these surfaces need not coincide. The construction demonstrates a failure mode of naive intuition, namely the temptation to equate an observer-dependent loss of signals or coordinates with a fundamental spacetime boundary, even though these are stress tests of definitions rather than physical predictions.

The JSON results should be read as parallel operational diagnostics rather than competing truths. For each sampled radius, the static observer’s redshift ratio shows a monotonic decline toward zero, and the summary fields identify the smallest $r_\mathrm{emit}$ still detectable above the chosen cutoff; this scale depends entirely on $z_\mathrm{min}$ and should not be over-interpreted as a geometric horizon. The infalling observer’s Painlevé–Gullstrand outgoing slope $dr/dt_\mathrm{PG}=1-\sqrt{2M/r}$ changes sign at $r=2M$, flagging a no-return surface that coincides with the event horizon in this simplified model. The accelerated observer’s horizon distance $x_h=1/a$ appears as a constant reference, illustrating that horizons can arise from observer motion alone; its numerical value should be connected conceptually to the acceleration scale, not to curvature or black hole physics.

---

## Toy 048 — Backreaction Threshold for Perturbations

This toy illustrates when a small gravitating object can no longer be treated as a harmless probe of a fixed spacetime. The physical setup is a Schwarzschild black hole of mass $M$ with a compact perturbing mass $m$ placed at radius $r$, all in units with $G=c=1$. The quantity of interest is a dimensionless measure of how strongly the perturbation distorts the background, estimated by the weak-field-inspired amplitude $\varepsilon \approx 2m/r$, alongside the mass ratio $q=m/M$.

The toy exists to expose a limitation rather than to predict dynamics: the breakdown of test-particle and linearized-gravity assumptions. In many calculations one assumes $m$ is “small,” but this is ambiguous unless tied to a concrete threshold. Here the stress test is whether the perturbation’s influence is parametrically small compared to the background, either in amplitude $\varepsilon$ or in relative curvature strength, crudely compared by $(m/r^3)/(M/r^3)=m/M=q$. When these quantities are no longer $\ll 1$, the toy demonstrates that backreaction is not optional and that linearization ceases to be self-consistent.

The JSON results should be read as a map of regimes rather than as physical outcomes. Each entry reports $(r,m)$ together with $q$, $\varepsilon$, simple validity flags, and a regime label; trends where increasing $m$ or decreasing $r$ push $\varepsilon$ and $q$ across their thresholds are what matter. Large values signal the need for self-force or fully nonlinear treatments, while small values indicate only that the approximations pass this proxy test. The numerical values of curvature or counts of regime labels should not be over-interpreted as predictions; they serve only to connect the abstract criteria embodied in $\varepsilon \approx 2m/r$ and $q=m/M$ back to concrete parameter choices.

---

## Toy 049 — Deliberately Broken Kretschmann Scaling

This toy evaluates curvature invariants for a Schwarzschild-like vacuum spacetime in geometric units ($G=c=1$), using a mass parameter $M$ and a set of sample radii $r$. The physical quantity of interest is the Kretschmann scalar $K$, a curvature invariant that, for the intended Schwarzschild baseline, scales as $K_\mathrm{correct}=48 M^2/r^6$; the toy also reports the Ricci scalar $R$, which is identically zero in the vacuum baseline. The setup is therefore “simple by design”: vary $r$ at fixed $M$ and watch how a known invariant should decay with distance from the source.

The toy exists to stress-test validation machinery by injecting a controlled, subtle theory/implementation error while keeping other signals “clean.” Specifically, it replaces the correct radial scaling with an intentionally wrong one-power law, $K_\mathrm{broken}=48 M^2/r^5$, while leaving $R=0$ so that only one invariant is inconsistent with the vacuum expectation. This demonstrates a failure mode where a model can look superficially plausible (right units, right qualitative decrease with $r$, correct horizon bookkeeping) yet still violate a key consistency check; the point is not physical prediction, but whether downstream comparators can reliably detect the mismatch via relative error and tolerance gating.

To interpret the JSON output, focus on `curvature_invariants.kretschmann_K_correct`, `curvature_invariants.kretschmann_K_broken`, and `curvature_invariants.kretschmann_relative_error`, along with the boolean `kretschmann_pass_within_tolerance` under `local_observables.consistency_checks`. The relative error here behaves like $|K_\mathrm{correct}-K_\mathrm{broken}|/|K_\mathrm{correct}|$ and, given the one-power mismatch, grows roughly linearly with radius (e.g., it is small only at contrived points such as $r=1$ in this sample, where the two expressions coincide numerically for $M=1$), so the sign/magnitude trend “more wrong as $r$ increases” is the intended red flag. Do not over-interpret the absolute values of $K$ as physical curvature measurements or the single passing point as model validity; instead, treat the pattern of failures (and the reported worst-case error and where it occurs) as confirmation that your harness is mapping the exported $K$ values back to the expected $1/r^6$ scaling and correctly rejecting deviations implied by the formulas.

---

## Toy 050 — Cross-toy Automated Comparison Harness

This toy does not model a spacetime directly; instead, it loads the JSON outputs of two other toys and compares quantities that are intended to be physically comparable. The setup is purely algorithmic: two datasets with matched coordinate sample points are aligned, and selected scalar values are checked for agreement within fixed absolute and relative tolerances. The quantity of interest is not a field itself but the discrepancy between two reported values, summarized conceptually by an error measure such as $|a-b|$ or $|a-b|/|a|$ for paired numbers $a$ and $b$ extracted from the inputs.

The toy exists to expose fragility and ambiguity in automated validation of physics codes, especially when “common” quantities are assumed to agree across implementations. It stress-tests the idea that invariants or observables with the same name should numerically coincide, illustrating how small parameter changes, schema differences, or missing fields can trigger failures even when nothing is physically inconsistent. This is not a prediction engine but a limitation probe: it demonstrates that pass/fail logic based on strict tolerances, e.g. declaring failure when $|a-b| > \varepsilon$, can conflate bookkeeping differences with genuine conceptual errors.

The JSON results should be read as a diagnostic report rather than data about spacetime. The `observables.summary` section indicates how many sample points aligned, how many numeric comparisons were actually performed, and whether any exceeded the specified tolerances, with `overall_pass` reflecting this bookkeeping outcome. In the example shown, all sample points align but no per-point numeric fields were comparable, while a small mismatch in the payload-level horizon radius causes failure; the sign and magnitude of that difference matter only relative to the chosen tolerances. These values should not be over-interpreted as physical discrepancies: they merely reflect how reported numbers relate to the comparison criteria, conceptually tying back to the simple error measures used to judge agreement.

---

